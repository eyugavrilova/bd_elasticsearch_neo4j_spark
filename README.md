# bd_elasticsearch_neo4j_spark
ТЗ

Elasticsearch.
1. Типы документов (json):
Пациент:
{index, doc_type, id, body: {id_пациента, персональные_данные*, путёвка, дата_прибытия, продолжительность_прибывания, [диагноз*], [id_процедуры]}}
Процедура:
{index, doc_type, id, body: {сведения_о_процедуре*,  стоимость}}
Примечание. Квадратные скобки [] обозначает тег (может быть несколько значений)
2. Требование к анализатору:
поля, отмеченные *, разделить на слова, убрать пунктуацию с помощью токенизатора standart (русский), перевести все токены в нижний регистр, убрать токены, находящиеся в списке стоп-слов, выполнить стемминг оставшихся токенов с помощью фильтра snowball.
3. Запросы с вложенной агрегацией:
- разбить пациентов по дате прибытия с периодом 1 год, для каждой «корзины» определить количество пациентов, прошедших каждую процедуру,
- определить стоимость процедуры по заданным ключевым словам.

Neo4j.
1. По данным из Elasticsearch заполнить графовую базу данных Пациент(id_пациента, дата_прибытия, персональные_данные) -  Прошёл(стоимость) - Процедура(id_процедуры).
Примечание.  В скобках приведены свойства узлов и отношений (связей).
2. Разработать и реализовать запрос: найти процедуру с максимальной суммарной стоимостью. 

Spark
1. По данным из Elasticsearch сформировать csv-файлы (с внутренней схемой) таблиц «Пациент», «Назначение», «Процедура» и сохранить их в файловой системе HDFS. 
2. Написать запрос select:  определить суммарное число назначений по каждой процедуре.
3. Реализовать этот запрос в Spark. Построить временную диаграмму его выполнения по результатам работы монитора.
